{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "feee14dc-aff3-4095-9fc0-5cdeafb6d3c4",
   "metadata": {},
   "source": [
    "<font size=\"6.5\"><b> TDD workflow </b></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d3f2b77-5b2a-4e42-a0f3-cf6029e5bdd0",
   "metadata": {},
   "source": [
    "# Testing & Cleaning functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d32a4eb-5a25-4883-b649-1fdf3d204343",
   "metadata": {},
   "source": [
    "## Importing libraries for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9ec85f17-f11d-498c-9e66-e63f5f266038",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from dateutil.parser import parse  # <-- For dates\n",
    "import re                          # <-- For phone numbers\n",
    "\n",
    "import pprint                      # <-- PrettyPrint: For printing summary dictionary\n",
    "from collections import OrderedDict # For reordering the PrettyPrint dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e3711c9b-170e-4502-99e8-e2afefd01871",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If the notebook is opened from the \"notebooks\" folder, we need to append the main directory to the \"python path\" so it sees all subfolders.\n",
    "import sys\n",
    "sys.path.append('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6475ca5f-16fd-409c-b045-026728fd67cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing my cleaning functions\n",
    "#from scripts.cleaning_functions import clean_dates, clean_phone, clean_geo, clean_email, clean_payment, extract_currency, clean_boolean, clean_name\n",
    "\n",
    "# Importing my testing functions\n",
    "from testing.test_functions import create_dirty_and_expected_data, test_cleaning, test_cleaning_report, test_cleaning_report_2, test_cleaning_report_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b55c3dfc-e2e6-4ecf-80e0-41deafa578c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a blank dataframe to store the messy and cleaned test-data\n",
    "df = pd.DataFrame(index=range(25))\n",
    "df_report = pd.DataFrame(index=[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f63dc54b-e05e-4f2b-8b0e-0b7278298033",
   "metadata": {},
   "source": [
    "## Preparation for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d023d326-4678-4a6f-8856-68479d9aca71",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Creating a blank dataframe to store the messy and cleaned test-data\n",
    "df = pd.DataFrame(index=range(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d253bf74-4416-487f-a865-05888190a016",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# The function to create test-cases\n",
    "\n",
    "def create_dirty_and_expected_data(df, dirty_column, expected_column, dirty_data_list, expected_data_list):\n",
    "    #Input arguments: \n",
    "        # 1. a DataFrame which the test data will be appended to, \n",
    "        # 2. name for the 'Dirty' column (str), \n",
    "        # 3. name for the 'Expected' column (str), \n",
    "        # 4. dirty data (list), \n",
    "        # 5. expected data (list)\n",
    "    #important assumption: df initially needs to be longer than the cases we define later\n",
    "    df[dirty_column] = dirty_data_list + [None] * (len(df) - len(dirty_data_list))\n",
    "    df[expected_column] = expected_data_list + [None] * (len(df) - len(expected_data_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7ae104ae-bf28-4846-a810-332542540cd7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# The function for applying any cleaning function, then comparing the result with the expected values\n",
    "\n",
    "def test_cleaning(clean_function, df, dirty_column, expected_column):\n",
    "    # Apply the cleaning function to the dirty column\n",
    "    cleaned_data = df[dirty_column].apply(clean_function)\n",
    "    \n",
    "    # Compare the cleaned data with the expected data\n",
    "    comparison_result = cleaned_data == df[expected_column]\n",
    "    \n",
    "    # Print the comparison result\n",
    "    print(\"Comparison Result:\")\n",
    "    for idx, (cleaned_value, expected_value) in enumerate(zip(cleaned_data, df[expected_column])):\n",
    "        if cleaned_value != expected_value:\n",
    "            print(f\"(Row {idx}) Cleaned Value: {cleaned_value} {type(cleaned_value)}, Expected Value: {expected_value} {type(expected_value)}, \")\n",
    "    \n",
    "    return comparison_result.all()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "839a5aba-4622-4a9e-a319-6d0a1fb23f1d",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Dealing with: Dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5e73c131-410b-4d73-8a69-dc9d9c458429",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.clean_date import clean_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fa8327d4-fbf1-4f11-897d-04313ce28957",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating uncleaned data and the expected data, to test our cleaning function\n",
    "\n",
    "create_dirty_and_expected_data(\n",
    "    df,\n",
    "    'dirty_dates',\n",
    "    'expected_dates',\n",
    "    [\n",
    "        'foo',\n",
    "        '2021-01-15',\n",
    "        '2021/02/20',\n",
    "        '2021.03.25',\n",
    "        '2021 04 30',\n",
    "        '31-01-2022',\n",
    "        '02/29/2023',  # Invalid date (leap year)\n",
    "        '2023.04.31',  # Invalid date (April 31st)\n",
    "        '2023-13-25',  # Invalid month (13)\n",
    "        '2023.11.32',  # Invalid day (November 32nd)\n",
    "        '2023/15/01',  # Incorrect order of elements\n",
    "        '1st Jan 2024', # Textual date\n",
    "        'Jan 15, 2024', # Textual date\n",
    "        '2024 February 25', # Textual date\n",
    "        '25th of March, 2024', # Textual date\n",
    "        'March 32nd, 2024', # Invalid day (March 32nd)\n",
    "        'April 5th, 2024', # Textual date\n",
    "        '20-30-2025',  # Ambiguous format\n",
    "        #'15/02/26',  # Ambiguous format\n",
    "        #'2026.25.03',  # Ambiguous format\n",
    "        #'2027/07/08',  # Ambiguous format\n",
    "    ],\n",
    "    [\n",
    "        'This_is_an_intentional_false_negative',\n",
    "        '2021-01-15',\n",
    "        '2021-02-20',\n",
    "        '2021-03-25',\n",
    "        '2021-04-30',\n",
    "        '2022-01-31',\n",
    "        None,  # Expected None for invalid date (02/29/2023)\n",
    "        None,  # Expected None for invalid date (2023.04.31)\n",
    "        None,  # Expected None for invalid date (2023-13-25)\n",
    "        None,  # Expected None for invalid date (2023.11.32)\n",
    "        '2023-01-15',  # Expected cleaned date for incorrect order of elements\n",
    "        '2024-01-01',  # Expected cleaned date for textual date (1st Jan 2024)\n",
    "        '2024-01-15',  # Expected cleaned date for textual date (Jan 15, 2024)\n",
    "        '2024-02-25',  # Expected cleaned date for textual date (2024 February 25)\n",
    "        '2024-03-25',  # Expected cleaned date for textual date (25th of March, 2024)\n",
    "        None,  # Expected None for invalid date (March 32nd, 2024)\n",
    "        '2024-04-05',  # Expected cleaned date for textual date (April 5th, 2024)\n",
    "        None,  # Ambiguous format (20-30-2025)\n",
    "        #None,  # Ambiguous format (15/02/26)\n",
    "        #None,  # Ambiguous format (2026.25.03)\n",
    "        #None,  # Ambiguous format (2027/07/08)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f53ad434-f816-4b3a-b565-6b06df371626",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparison Result:\n",
      "(Row 0) Cleaned Value: None <class 'NoneType'>, Expected Value: This_is_an_intentional_false_negative <class 'str'>, \n",
      "(Row 10) Cleaned Value: None <class 'NoneType'>, Expected Value: 2023-01-15 <class 'str'>, \n"
     ]
    }
   ],
   "source": [
    "# Run the testing function\n",
    "result = test_cleaning_report(clean_date, df, df_report, 'dirty_dates', 'expected_dates')\n",
    "\n",
    "# Printing the cleaning result\n",
    "#print(pprint.pformat(OrderedDict(cleaning_summary_date), indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4c670647-a825-47a4-98b9-68cc4d26ec3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   dirty_dates_nulls_encountered  dirty_dates_parsing_success  \\\n",
      "0                              2                           10   \n",
      "\n",
      "   dirty_dates_parsing_failed  \n",
      "0                           8  \n"
     ]
    }
   ],
   "source": [
    "# Running the actual cleaning\n",
    "df['cleaned_dates'] = df['dirty_dates'].apply(clean_date, df_report=df_report, dirty_column_name='dirty_dates')\n",
    "print(df_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eae9c3c9-64d6-4978-be7c-5c5b2a4402f0",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### dates: delete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fca6d575-4e59-4358-98d1-0a0c7024b08a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a global dictionary to track cleaning actions\n",
    "#IMPORTANT: Needs to be resetted to 0, before .apply()-ing each cleaning_function in order to show valid counters\n",
    "cleaning_summary_date = {\n",
    "    \"null_values_encountered\": 0,\n",
    "    \"date_parsing_success\": 0,\n",
    "    \"date_parsing_failed\": 0,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "400541e4-a3df-49e7-90a5-411eed52636b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the cleaning function\n",
    "\n",
    "def clean_dates(x):\n",
    "    global cleaning_summary_date\n",
    "    \n",
    "    # Skip Null values\n",
    "    if pd.isna(x):\n",
    "        cleaning_summary_date[\"null_values_encountered\"] += 1\n",
    "        return None\n",
    "    \n",
    "    try:\n",
    "        # Attempt to parse the date using dateutil.parser.parse\n",
    "        date_obj = parse(x, fuzzy=True)\n",
    "        cleaning_summary_date[\"date_parsing_success\"] += 1\n",
    "        return date_obj.strftime('%Y-%m-%d')  # Convert date to YYYY-MM-DD format\n",
    "    except Exception as e:\n",
    "        cleaning_summary_date[\"date_parsing_failed\"] += 1\n",
    "        return None  # Return None if parsing fails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b4429919-f560-4121-8938-5a4f95f5db5a",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cleaning_summary_date' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mE:\\_Programming\\_DataAnalysis\\Salary_data_combined\\notebooks\\..\\scripts\\cleaning_functions.py\u001b[0m in \u001b[0;36mclean_dates\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m     26\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m         \u001b[0mcleaning_summary_date\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"null_values_encountered\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'cleaning_summary_date' is not defined",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_10600\\3812542153.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Run the testing function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest_cleaning\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclean_dates\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'dirty_dates'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'expected_dates'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# Printing the cleaning result\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpprint\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mOrderedDict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcleaning_summary_date\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindent\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\_Programming\\_DataAnalysis\\Salary_data_combined\\notebooks\\..\\testing\\test_functions.py\u001b[0m in \u001b[0;36mtest_cleaning\u001b[1;34m(clean_function, df, dirty_column, expected_column)\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m     \u001b[1;31m# Apply the cleaning function to the dirty column, and store the result in a new generic \"cleaned_data\" columns.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m     \u001b[0mcleaned_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdirty_column\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclean_function\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m     \u001b[1;31m# Compare the cleaned data with the expected data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\myNewEnv\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36mapply\u001b[1;34m(self, func, convert_dtype, args, **kwargs)\u001b[0m\n\u001b[0;32m   4769\u001b[0m         \u001b[0mdtype\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mfloat64\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4770\u001b[0m         \"\"\"\n\u001b[1;32m-> 4771\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mSeriesApply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconvert_dtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4772\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4773\u001b[0m     def _reduce(\n",
      "\u001b[1;32m~\\anaconda3\\envs\\myNewEnv\\lib\\site-packages\\pandas\\core\\apply.py\u001b[0m in \u001b[0;36mapply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1121\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1122\u001b[0m         \u001b[1;31m# self.f is Callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1123\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_standard\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1124\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1125\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0magg\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\myNewEnv\\lib\\site-packages\\pandas\\core\\apply.py\u001b[0m in \u001b[0;36mapply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1172\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1173\u001b[0m                 \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1174\u001b[1;33m                 mapped = lib.map_infer(\n\u001b[0m\u001b[0;32m   1175\u001b[0m                     \u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1176\u001b[0m                     \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\myNewEnv\\lib\\site-packages\\pandas\\_libs\\lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mE:\\_Programming\\_DataAnalysis\\Salary_data_combined\\notebooks\\..\\scripts\\cleaning_functions.py\u001b[0m in \u001b[0;36mclean_dates\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m     28\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     31\u001b[0m         \u001b[1;31m# Attempt to parse the date using dateutil.parser.parse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m         \u001b[0mdate_obj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfuzzy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'cleaning_summary_date' is not defined"
     ]
    }
   ],
   "source": [
    "# Run the testing function\n",
    "result = test_cleaning(clean_dates, df, 'dirty_dates', 'expected_dates')\n",
    "\n",
    "# Printing the cleaning result\n",
    "print(pprint.pformat(OrderedDict(cleaning_summary_date), indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2e10edd3-8e82-4e24-a5ef-d39df617de58",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cleaning_summary_date' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_15804\\3352129613.py\u001b[0m in \u001b[0;36mclean_dates\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[0mdate_obj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfuzzy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m         \u001b[0mcleaning_summary_date\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"date_parsing_success\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mdate_obj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrftime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'%Y-%m-%d'\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# Convert date to YYYY-MM-DD format\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'cleaning_summary_date' is not defined",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_15804\\3869017286.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Running the actual cleaning\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'cleaned_dates'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'dirty_dates'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclean_dates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\myNewEnv\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36mapply\u001b[1;34m(self, func, convert_dtype, args, **kwargs)\u001b[0m\n\u001b[0;32m   4769\u001b[0m         \u001b[0mdtype\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mfloat64\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4770\u001b[0m         \"\"\"\n\u001b[1;32m-> 4771\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mSeriesApply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconvert_dtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4772\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4773\u001b[0m     def _reduce(\n",
      "\u001b[1;32m~\\anaconda3\\envs\\myNewEnv\\lib\\site-packages\\pandas\\core\\apply.py\u001b[0m in \u001b[0;36mapply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1121\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1122\u001b[0m         \u001b[1;31m# self.f is Callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1123\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_standard\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1124\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1125\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0magg\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\myNewEnv\\lib\\site-packages\\pandas\\core\\apply.py\u001b[0m in \u001b[0;36mapply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1172\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1173\u001b[0m                 \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1174\u001b[1;33m                 mapped = lib.map_infer(\n\u001b[0m\u001b[0;32m   1175\u001b[0m                     \u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1176\u001b[0m                     \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\myNewEnv\\lib\\site-packages\\pandas\\_libs\\lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_15804\\3352129613.py\u001b[0m in \u001b[0;36mclean_dates\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m     15\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mdate_obj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrftime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'%Y-%m-%d'\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# Convert date to YYYY-MM-DD format\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m         \u001b[0mcleaning_summary_date\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"date_parsing_failed\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[1;32mNone\u001b[0m  \u001b[1;31m# Return None if parsing fails\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'cleaning_summary_date' is not defined"
     ]
    }
   ],
   "source": [
    "# Running the actual cleaning\n",
    "df['cleaned_dates'] = df['dirty_dates'].apply(clean_dates)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f12e34eb-e594-4c14-9e0e-9efd35a9d844",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Dealing with: Phone Numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "de56a36c-f06c-41ac-a70c-03d9248d94d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.clean_phone import clean_phone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d3de6bb3-035c-4a1f-a3e5-aef46f567bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating uncleaned data and the expected data, to test our cleaning function\n",
    "\n",
    "create_dirty_and_expected_data(\n",
    "    df,\n",
    "    'dirty_phone',\n",
    "    'expected_phone',\n",
    "    [\n",
    "        'foo',\n",
    "        '+1 (123) 456-7890',\n",
    "        '123-456-7890',\n",
    "        '(111) 222 3333',\n",
    "        '+44 1234 567890',\n",
    "        '001-345-678-9012',\n",
    "        '555-5555',\n",
    "        '1234567890',\n",
    "        '+1 234 567 8901 ext. 1234',\n",
    "        'invalid_phone_number',\n",
    "        '123-456-7890 x123',\n",
    "        '234-567-8901 ext. 1234',\n",
    "        '(+1) 1234567890',\n",
    "        '+1 (1234) 567-890',\n",
    "        '1234-567-890',\n",
    "        '(123) 456-7890',\n",
    "        '123.456.7890',\n",
    "        '+123 456 7890',\n",
    "        '123456789',  # Too short\n",
    "        '+12345678901',  # Too long\n",
    "        '+1 (123) 456-789A',  # Invalid character\n",
    "    ],\n",
    "    [\n",
    "        'This_is_an_intentional_false_negative',\n",
    "        '+1 (123) 456-7890',\n",
    "        '123-456-7890',\n",
    "        '(111) 222 3333',\n",
    "        '+44 1234 567890',\n",
    "        '001-345-678-9012',\n",
    "        '555-5555',\n",
    "        '1234567890',\n",
    "        '+1 234 567 8901 ext. 1234',\n",
    "        None,  # For 'invalid_phone_number'\n",
    "        '123-456-7890 x123',\n",
    "        '234-567-8901 ext. 1234',\n",
    "        None,  # For '(+1) 1234567890'\n",
    "        '+1 (1234) 567-890',\n",
    "        '1234-567-890',\n",
    "        '(123) 456-7890',\n",
    "        '123.456.7890',\n",
    "        '+123 456 7890',\n",
    "        None,  # For '123456789'\n",
    "        None,  # For '+12345678901'\n",
    "        None   # For '+1 (123) 456-789A'\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "1417a31b-b85f-406f-b07a-fd9548c1558c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparison Result:\n",
      "(Row 0) Cleaned Value: None <class 'NoneType'>, Expected Value: This_is_an_intentional_false_negative <class 'str'>, \n",
      "(Row 1) Cleaned Value: 11234567890 <class 'str'>, Expected Value: +1 (123) 456-7890 <class 'str'>, \n",
      "(Row 2) Cleaned Value: +11234567890 <class 'str'>, Expected Value: 123-456-7890 <class 'str'>, \n",
      "(Row 3) Cleaned Value: +11112223333 <class 'str'>, Expected Value: (111) 222 3333 <class 'str'>, \n",
      "(Row 4) Cleaned Value: 441234567890 <class 'str'>, Expected Value: +44 1234 567890 <class 'str'>, \n",
      "(Row 5) Cleaned Value: 0013456789012 <class 'str'>, Expected Value: 001-345-678-9012 <class 'str'>, \n",
      "(Row 6) Cleaned Value: None <class 'NoneType'>, Expected Value: 555-5555 <class 'str'>, \n",
      "(Row 7) Cleaned Value: +11234567890 <class 'str'>, Expected Value: 1234567890 <class 'str'>, \n",
      "(Row 8) Cleaned Value: 12345678901 <class 'str'>, Expected Value: +1 234 567 8901 ext. 1234 <class 'str'>, \n",
      "(Row 10) Cleaned Value: 1234567890123 <class 'str'>, Expected Value: 123-456-7890 x123 <class 'str'>, \n",
      "(Row 11) Cleaned Value: +12345678901 <class 'str'>, Expected Value: 234-567-8901 ext. 1234 <class 'str'>, \n",
      "(Row 12) Cleaned Value: 11234567890 <class 'str'>, Expected Value: None <class 'NoneType'>, \n",
      "(Row 13) Cleaned Value: 11234567890 <class 'str'>, Expected Value: +1 (1234) 567-890 <class 'str'>, \n",
      "(Row 14) Cleaned Value: +11234567890 <class 'str'>, Expected Value: 1234-567-890 <class 'str'>, \n",
      "(Row 15) Cleaned Value: +11234567890 <class 'str'>, Expected Value: (123) 456-7890 <class 'str'>, \n",
      "(Row 16) Cleaned Value: +11234567890 <class 'str'>, Expected Value: 123.456.7890 <class 'str'>, \n",
      "(Row 17) Cleaned Value: +11234567890 <class 'str'>, Expected Value: +123 456 7890 <class 'str'>, \n",
      "(Row 19) Cleaned Value: 12345678901 <class 'str'>, Expected Value: None <class 'NoneType'>, \n",
      "(Row 20) Cleaned Value: +11123456789 <class 'str'>, Expected Value: None <class 'NoneType'>, \n"
     ]
    }
   ],
   "source": [
    "# Run the testing function\n",
    "result = test_cleaning_report(clean_phone, df, df_report, 'dirty_phone', 'expected_phone')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ecf05f7d-c042-4c16-b98d-a3f5a19de50b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   dirty_dates_nulls_encountered  dirty_dates_parsing_success  \\\n",
      "0                              3                           10   \n",
      "\n",
      "   dirty_dates_parsing_failed  dirty_phonenull_values_encountered  \\\n",
      "0                           7                                   0   \n",
      "\n",
      "   dirty_phonevalid_phone_numbers  dirty_phoneinvalid_phone_numbers  \\\n",
      "0                              17                                 3   \n",
      "\n",
      "   dirty_geo_null_values_encountered  dirty_geo_leading_trailing_whitespace  \\\n",
      "0                                 15                                      1   \n",
      "\n",
      "   dirty_geo_converted_to_float  dirty_geo_ValueError --> None  ...  \\\n",
      "0                             3                              2  ...   \n",
      "\n",
      "   dirty_email_leading_trailing_whitespace  dirty_email_spaces_in_domain_name  \\\n",
      "0                                        1                                  3   \n",
      "\n",
      "   dirty_email_double_periods_in_domain_name  dirty_email_double_at_symbols  \\\n",
      "0                                          1                              1   \n",
      "\n",
      "   dirty_email_hyphens_in_domain_name  dirty_email_invalid_email_pattern  \\\n",
      "0                                   2                                  9   \n",
      "\n",
      "   dirty_email_valid_emails  dirty_phone_null_values_encountered  \\\n",
      "0                         9                                    0   \n",
      "\n",
      "   dirty_phone_valid_phone_numbers  dirty_phone_invalid_phone_numbers  \n",
      "0                               17                                  3  \n",
      "\n",
      "[1 rows x 37 columns]\n"
     ]
    }
   ],
   "source": [
    "# Running the actual cleaning\n",
    "df['cleaned_phone'] = df['dirty_phone'].apply(clean_phone, df_report=df_report, dirty_column_name='dirty_phone')\n",
    "print(df_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69961cc9-a0ac-46d4-94dd-13c459bf6f3e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Phones: Delete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f98d7417-2bda-4386-a401-aa4f89fffd95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a global dictionary to track cleaning actions\n",
    "#IMPORTANT: Needs to be resetted to 0, before .apply()-ing each cleaning_function in order to show valid counters\n",
    "cleaning_summary_phone = {\n",
    "    \"null_values_encountered\": 0,\n",
    "    \"date_parsing_success\": 0,\n",
    "    \"date_parsing_failed\": 0,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "3b16c3e9-3944-4419-bc7f-3f15636ea020",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The cleaning function\n",
    "\n",
    "def clean_phone(phone_number):\n",
    "    global cleaning_summary_phone\n",
    "    \n",
    "    # Skip Null values\n",
    "    if pd.isna(date_str):\n",
    "        cleaning_summary_phone[\"null_values_encountered\"] += 1\n",
    "        return None\n",
    "    \n",
    "    # Regular expression pattern to match valid phone numbers\n",
    "    pattern = r'\\+?[0-9]+(?:\\s*[\\-()x.]?\\s*[0-9]+)*'\n",
    "    \n",
    "    # Find all phone number matches in the input string\n",
    "    matches = re.findall(pattern, phone_number)\n",
    "    \n",
    "    # If no matches found, return None\n",
    "    if not matches:\n",
    "        return None\n",
    "    \n",
    "    # Select the first match as the cleaned phone number\n",
    "    cleaned_phone_number = matches[0]\n",
    "    \n",
    "    # Remove non-numeric characters\n",
    "    cleaned_phone_number = re.sub(r'\\D', '', cleaned_phone_number)\n",
    "    \n",
    "    # Check if the cleaned phone number has a valid length\n",
    "    if len(cleaned_phone_number) < 10 or len(cleaned_phone_number) > 15:\n",
    "        return None\n",
    "    \n",
    "    # Add country code if missing\n",
    "    if len(cleaned_phone_number) == 10:\n",
    "        cleaned_phone_number = '+1' + cleaned_phone_number\n",
    "    \n",
    "    return cleaned_phone_number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "250e20a0-94d0-44e4-b4b5-6133bab25c06",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'date_str' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_15804\\1188301316.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Running the actual cleaning\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'cleaned_phone'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'dirty_phone'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclean_phone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\myNewEnv\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36mapply\u001b[1;34m(self, func, convert_dtype, args, **kwargs)\u001b[0m\n\u001b[0;32m   4769\u001b[0m         \u001b[0mdtype\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mfloat64\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4770\u001b[0m         \"\"\"\n\u001b[1;32m-> 4771\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mSeriesApply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconvert_dtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4772\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4773\u001b[0m     def _reduce(\n",
      "\u001b[1;32m~\\anaconda3\\envs\\myNewEnv\\lib\\site-packages\\pandas\\core\\apply.py\u001b[0m in \u001b[0;36mapply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1121\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1122\u001b[0m         \u001b[1;31m# self.f is Callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1123\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_standard\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1124\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1125\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0magg\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\myNewEnv\\lib\\site-packages\\pandas\\core\\apply.py\u001b[0m in \u001b[0;36mapply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1172\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1173\u001b[0m                 \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1174\u001b[1;33m                 mapped = lib.map_infer(\n\u001b[0m\u001b[0;32m   1175\u001b[0m                     \u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1176\u001b[0m                     \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\myNewEnv\\lib\\site-packages\\pandas\\_libs\\lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_15804\\3226230207.py\u001b[0m in \u001b[0;36mclean_phone\u001b[1;34m(phone_number)\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;31m# Skip Null values\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m     \u001b[1;32mif\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdate_str\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m         \u001b[0mcleaning_summary_phone\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"null_values_encountered\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'date_str' is not defined"
     ]
    }
   ],
   "source": [
    "# Running the actual cleaning\n",
    "df['cleaned_phone'] = df['dirty_phone'].apply(clean_phone)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "83d87def-24fc-492b-add1-e24c83ff2fc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          dirty_phone_numbers\n",
      "0           +1 (123) 456-7890\n",
      "1                123-456-7890\n",
      "2              (111) 222 3333\n",
      "3             +44 1234 567890\n",
      "4            001-345-678-9012\n",
      "5                    555-5555\n",
      "6                  1234567890\n",
      "7   +1 234 567 8901 ext. 1234\n",
      "8        invalid_phone_number\n",
      "9           123-456-7890 x123\n",
      "10     234-567-8901 ext. 1234\n",
      "11            (+1) 1234567890\n",
      "12          +1 (1234) 567-890\n",
      "13               1234-567-890\n",
      "14             (123) 456-7890\n",
      "15               123.456.7890\n",
      "16              +123 456 7890\n",
      "17                  123456789\n",
      "18               +12345678901\n",
      "19          +1 (123) 456-789A\n"
     ]
    }
   ],
   "source": [
    "data = {\n",
    "    'dirty_phone_numbers': [\n",
    "        '+1 (123) 456-7890',\n",
    "        '123-456-7890',\n",
    "        '(111) 222 3333',\n",
    "        '+44 1234 567890',\n",
    "        '001-345-678-9012',\n",
    "        '555-5555',\n",
    "        '1234567890',\n",
    "        '+1 234 567 8901 ext. 1234',\n",
    "        'invalid_phone_number',\n",
    "        '123-456-7890 x123',\n",
    "        '234-567-8901 ext. 1234',\n",
    "        '(+1) 1234567890',\n",
    "        '+1 (1234) 567-890',\n",
    "        '1234-567-890',\n",
    "        '(123) 456-7890',\n",
    "        '123.456.7890',\n",
    "        '+123 456 7890',\n",
    "        '123456789',  # Too short\n",
    "        '+12345678901',  # Too long\n",
    "        '+1 (123) 456-789A',  # Invalid character\n",
    "    ]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "47c6d600-7310-4c50-9c7c-71bab24ab74e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'clean_phone_numbers' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_15804\\4095883034.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Test the cleaning function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mtest_phone_number\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'+1 (123) 456-7890'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mcleaned_phone_number\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclean_phone_numbers\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_phone_number\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcleaned_phone_number\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# Output: +11234567890\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'clean_phone_numbers' is not defined"
     ]
    }
   ],
   "source": [
    "# Test the cleaning function\n",
    "test_phone_number = '+1 (123) 456-7890'\n",
    "cleaned_phone_number = clean_phone_numbers(test_phone_number)\n",
    "print(cleaned_phone_number)  # Output: +11234567890"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0929d25d-0493-4cac-9a38-9cac37f40746",
   "metadata": {},
   "source": [
    "## Dealing with: Geolocation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "91abf2a1-b2ed-4698-bbef-b5abe481262a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.clean_geolocation import clean_geo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f53d2c73-1b48-4d40-bc6e-16feae3d4f6b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Creating uncleaned data and the expected data, to test our cleaning function\n",
    "create_dirty_and_expected_data(\n",
    "    df,\n",
    "    'dirty_geo',\n",
    "    'expected_geo',\n",
    "    [\n",
    "        'foo',\n",
    "        '89.123456',           # Valid latitude\n",
    "        '-91.5678',            # Invalid latitude (out of range)\n",
    "        'xyz',                 # Invalid latitude (non-numeric)\n",
    "        '45.678.90',           # Invalid latitude (contains multiple dots)\n",
    "        '  -12.345  ',         # Dirty latitude with leading and trailing spaces\n",
    "    ],\n",
    "    [\n",
    "        'This_is_an_intentional_false_negative',\n",
    "        89.123456,   # Valid latitude\n",
    "        None,          # Invalid latitude (out of range)\n",
    "        None,          # Invalid latitude (non-numeric)\n",
    "        None,          # Invalid latitude (contains multiple dots)\n",
    "        -12.345,     # Cleaned latitude (leading and trailing spaces removed)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "9b01c738-de49-4da5-b391-57690b15dcc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparison Result:\n",
      "(Row 0) Cleaned Value: nan <class 'float'>, Expected Value: This_is_an_intentional_false_negative <class 'str'>, \n",
      "(Row 2) Cleaned Value: nan <class 'float'>, Expected Value: None <class 'NoneType'>, \n",
      "(Row 3) Cleaned Value: nan <class 'float'>, Expected Value: None <class 'NoneType'>, \n",
      "(Row 4) Cleaned Value: nan <class 'float'>, Expected Value: None <class 'NoneType'>, \n",
      "(Row 6) Cleaned Value: nan <class 'float'>, Expected Value: None <class 'NoneType'>, \n",
      "(Row 7) Cleaned Value: nan <class 'float'>, Expected Value: None <class 'NoneType'>, \n",
      "(Row 8) Cleaned Value: nan <class 'float'>, Expected Value: None <class 'NoneType'>, \n",
      "(Row 9) Cleaned Value: nan <class 'float'>, Expected Value: None <class 'NoneType'>, \n",
      "(Row 10) Cleaned Value: nan <class 'float'>, Expected Value: None <class 'NoneType'>, \n",
      "(Row 11) Cleaned Value: nan <class 'float'>, Expected Value: None <class 'NoneType'>, \n",
      "(Row 12) Cleaned Value: nan <class 'float'>, Expected Value: None <class 'NoneType'>, \n",
      "(Row 13) Cleaned Value: nan <class 'float'>, Expected Value: None <class 'NoneType'>, \n",
      "(Row 14) Cleaned Value: nan <class 'float'>, Expected Value: None <class 'NoneType'>, \n",
      "(Row 15) Cleaned Value: nan <class 'float'>, Expected Value: None <class 'NoneType'>, \n",
      "(Row 16) Cleaned Value: nan <class 'float'>, Expected Value: None <class 'NoneType'>, \n",
      "(Row 17) Cleaned Value: nan <class 'float'>, Expected Value: None <class 'NoneType'>, \n",
      "(Row 18) Cleaned Value: nan <class 'float'>, Expected Value: None <class 'NoneType'>, \n",
      "(Row 19) Cleaned Value: nan <class 'float'>, Expected Value: None <class 'NoneType'>, \n",
      "(Row 20) Cleaned Value: nan <class 'float'>, Expected Value: None <class 'NoneType'>, \n",
      "(Row 21) Cleaned Value: nan <class 'float'>, Expected Value: None <class 'NoneType'>, \n",
      "(Row 22) Cleaned Value: nan <class 'float'>, Expected Value: None <class 'NoneType'>, \n",
      "(Row 23) Cleaned Value: nan <class 'float'>, Expected Value: None <class 'NoneType'>, \n",
      "(Row 24) Cleaned Value: nan <class 'float'>, Expected Value: None <class 'NoneType'>, \n"
     ]
    }
   ],
   "source": [
    "# Run the testing function\n",
    "result = test_cleaning_report(clean_geo, df, df_report, 'dirty_geo', 'expected_geo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "647a7393-556e-4515-a679-3fd1d555a3cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" NaN vs. None\"\"\"\n",
    "\n",
    "df['cleaned_geo'].replace({pd.np.nan: None}, inplace=True)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e9a32769-c7b3-455b-8866-59937a57a3eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   dirty_dates_nulls_encountered  dirty_dates_parsing_success  \\\n",
      "0                              3                           10   \n",
      "\n",
      "   dirty_dates_parsing_failed  dirty_phonenull_values_encountered  \\\n",
      "0                           7                                   0   \n",
      "\n",
      "   dirty_phonevalid_phone_numbers  dirty_phoneinvalid_phone_numbers  \\\n",
      "0                              17                                 3   \n",
      "\n",
      "   dirty_geo_null_values_encountered  dirty_geo_leading_trailing_whitespace  \\\n",
      "0                                 15                                      1   \n",
      "\n",
      "   dirty_geo_converted_to_float  dirty_geo_ValueError --> None  \\\n",
      "0                             3                              2   \n",
      "\n",
      "   dirty_geo_string --> None  dirty_geo_Number out of scope  \n",
      "0                          0                              1  \n"
     ]
    }
   ],
   "source": [
    "df['cleaned_geo'] = df['dirty_geo'].apply(clean_geo, df_report=df_report, dirty_column_name='dirty_geo')\n",
    "print(df_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa878f76-c30c-4392-bbc3-05e46a36836f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Geo: Delete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "b072dc42-f164-4bab-a70c-33d609a33a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a global dictionary to track cleaning actions\n",
    "#IMPORTANT: Needs to be resetted to 0, before .apply()-ing each cleaning_function in order to show valid counters\n",
    "cleaning_summary_geo = {\n",
    "    \"null_values_encountered\": 0,\n",
    "    \"leading_trailing_whitespace\": 0,\n",
    "    \"converted_to_float\": 0,\n",
    "    \"ValueError --> None\": 0,\n",
    "    \"string --> None\": 0,\n",
    "    \"Number out of scope\": 0,   \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ccafafae-18ac-4a7e-8610-ba8f4ab1be73",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_geo(x):\n",
    "    #global cleaning_summary_geo \n",
    "    \n",
    "    # Skip Null values\n",
    "    if pd.isna(x):\n",
    "        cleaning_summary_geo[\"null_values_encountered\"] += 1\n",
    "        return None\n",
    "\n",
    "    # Whitespace stripping\n",
    "    original_x = x\n",
    "    x = x.strip()\n",
    "    if x != original_x:\n",
    "        cleaning_summary_geo[\"leading_trailing_whitespace\"] += 1\n",
    "    \n",
    "    # Trying to convert to float, except returning None if it fails\n",
    "    try:\n",
    "        original_x = x\n",
    "        x = float(x)\n",
    "        if x != original_x:\n",
    "            cleaning_summary_geo[\"converted_to_float\"] += 1\n",
    "    except ValueError:\n",
    "        cleaning_summary_geo[\"ValueError --> None\"] += 1\n",
    "        return None\n",
    "\n",
    "    #fails to convert to float, they remain a string, and none\n",
    "    # Check if it's a string\n",
    "    if isinstance(x, str):\n",
    "        cleaning_summary_geo[\"string --> None\"] += 1\n",
    "        return None\n",
    "    \n",
    "    \n",
    "    if not (-90 <= x <= 90):\n",
    "        cleaning_summary_geo[\"Number out of scope\"] += 1\n",
    "        return None\n",
    "    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "aa3320d0-2e0e-445c-9fd0-804536b5a754",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparison Result:\n",
      "(Row 1) Cleaned Value: nan <class 'float'>, Expected Value: nan <class 'float'>, \n",
      "(Row 2) Cleaned Value: nan <class 'float'>, Expected Value: nan <class 'float'>, \n",
      "(Row 3) Cleaned Value: nan <class 'float'>, Expected Value: nan <class 'float'>, \n",
      "(Row 5) Cleaned Value: nan <class 'float'>, Expected Value: nan <class 'float'>, \n",
      "(Row 6) Cleaned Value: nan <class 'float'>, Expected Value: nan <class 'float'>, \n",
      "(Row 7) Cleaned Value: nan <class 'float'>, Expected Value: nan <class 'float'>, \n",
      "(Row 8) Cleaned Value: nan <class 'float'>, Expected Value: nan <class 'float'>, \n",
      "(Row 9) Cleaned Value: nan <class 'float'>, Expected Value: nan <class 'float'>, \n",
      "(Row 10) Cleaned Value: nan <class 'float'>, Expected Value: nan <class 'float'>, \n",
      "(Row 11) Cleaned Value: nan <class 'float'>, Expected Value: nan <class 'float'>, \n",
      "(Row 12) Cleaned Value: nan <class 'float'>, Expected Value: nan <class 'float'>, \n",
      "(Row 13) Cleaned Value: nan <class 'float'>, Expected Value: nan <class 'float'>, \n",
      "(Row 14) Cleaned Value: nan <class 'float'>, Expected Value: nan <class 'float'>, \n",
      "(Row 15) Cleaned Value: nan <class 'float'>, Expected Value: nan <class 'float'>, \n",
      "(Row 16) Cleaned Value: nan <class 'float'>, Expected Value: nan <class 'float'>, \n",
      "(Row 17) Cleaned Value: nan <class 'float'>, Expected Value: nan <class 'float'>, \n",
      "(Row 18) Cleaned Value: nan <class 'float'>, Expected Value: nan <class 'float'>, \n",
      "(Row 19) Cleaned Value: nan <class 'float'>, Expected Value: nan <class 'float'>, \n",
      "OrderedDict([   ('null_values_encountered', 15),\n",
      "                ('leading_trailing_whitespace', 1),\n",
      "                ('converted_to_float', 3),\n",
      "                ('ValueError --> None', 2),\n",
      "                ('string --> None', 0),\n",
      "                ('Number out of scope', 1)])\n"
     ]
    }
   ],
   "source": [
    "result = test_cleaning(clean_geo, df, 'dirty_geo', 'expected_geo')\n",
    "\n",
    "# Printing the cleaning result\n",
    "print(pprint.pformat(OrderedDict(cleaning_summary_geo), indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "c22da27b-0226-411e-9410-82896f4a600d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          dirty_phone_numbers    dirty_geo  expected_geo cleaned_geo\n",
      "0           +1 (123) 456-7890    89.123456     89.123456   89.123456\n",
      "1                123-456-7890     -91.5678           NaN        None\n",
      "2              (111) 222 3333          xyz           NaN        None\n",
      "3             +44 1234 567890    45.678.90           NaN        None\n",
      "4            001-345-678-9012    -12.345      -12.345000     -12.345\n",
      "5                    555-5555         None           NaN        None\n",
      "6                  1234567890         None           NaN        None\n",
      "7   +1 234 567 8901 ext. 1234         None           NaN        None\n",
      "8        invalid_phone_number         None           NaN        None\n",
      "9           123-456-7890 x123         None           NaN        None\n",
      "10     234-567-8901 ext. 1234         None           NaN        None\n",
      "11            (+1) 1234567890         None           NaN        None\n",
      "12          +1 (1234) 567-890         None           NaN        None\n",
      "13               1234-567-890         None           NaN        None\n",
      "14             (123) 456-7890         None           NaN        None\n",
      "15               123.456.7890         None           NaN        None\n",
      "16              +123 456 7890         None           NaN        None\n",
      "17                  123456789         None           NaN        None\n",
      "18               +12345678901         None           NaN        None\n",
      "19          +1 (123) 456-789A         None           NaN        None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Viktor\\AppData\\Local\\Temp\\ipykernel_15804\\1027826470.py:3: FutureWarning: The pandas.np module is deprecated and will be removed from pandas in a future version. Import numpy directly instead.\n",
      "  df['cleaned_geo'].replace({pd.np.nan: None}, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# Running the actual cleaning\n",
    "df['cleaned_geo'] = df['dirty_geo'].apply(clean_geo)\n",
    "df['cleaned_geo'].replace({pd.np.nan: None}, inplace=True)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3496a7ba-841b-46b8-b0f7-f14cec36505f",
   "metadata": {},
   "source": [
    "## Dealing with: email adresses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6e5a3547-1ca2-4508-85af-6cc0b62ccfdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.clean_email import clean_email"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "79d795ae-6c0c-4c9c-ab4d-d317b815e1b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_dirty_and_expected_data(\n",
    "    df,\n",
    "    'dirty_email',\n",
    "    'expected_email',\n",
    "    [\n",
    "    'foo',\n",
    "    'john.doe@example.com',  # Valid email address\n",
    "    'jane.doe@example',      # Missing top-level domain\n",
    "    'invalid.email@',        # Missing domain name\n",
    "    'test@example',          # Missing top-level domain and domain name\n",
    "    'test@.com',             # Missing domain name\n",
    "    'test@example.',         # Missing top-level domain\n",
    "    'test@com',              # Missing top-level domain separator\n",
    "    '@example.com',          # Missing local part\n",
    "    'test@exam ple.com',     # Space in local part\n",
    "    'test@example .com',     # Space in domain name\n",
    "    ' test @example .com ',  # Spaces everywhere\n",
    "    'test@@example.com',     # Double @ symbol\n",
    "    'test@example..com',     # Double period in domain name\n",
    "    'test@-example.com',     # Hyphen at the beginning of domain name\n",
    "    'test@example-.com',     # Hyphen at the end of domain name\n",
    "    'test@exa_mple.com',     # Underscore in domain name\n",
    "    'test@[example].com',    # Square brackets in domain name\n",
    "    'test@example.c'        # Invalid top-level domain\n",
    "    ],\n",
    "    [\n",
    "    'This_is_an_intentional_false_negative',\n",
    "    'john.doe@example.com',  # Valid email address\n",
    "    None,      # Missing top-level domain\n",
    "    None,        # Missing domain name\n",
    "    None,          # Missing top-level domain and domain name\n",
    "    None,             # Missing domain name\n",
    "    None,         # Missing top-level domain\n",
    "    None,              # Missing top-level domain separator\n",
    "    None,          # Missing local part\n",
    "    'test@example.com',     # Space in local part\n",
    "    'test@example.com',     # Space in domain name\n",
    "    'test@example.com',     # Spaces everywhere\n",
    "    'test@example.com',     # Double @ symbol\n",
    "    'test@example.com',     # Double period in domain name\n",
    "    'test@example.com',     # Hyphen at the beginning of domain name\n",
    "    'test@example.com',     # Hyphen at the end of domain name\n",
    "    'test@exa_mple.com',     # Underscore in domain name\n",
    "    'test@[example].com',    # Square brackets in domain name\n",
    "    None        # Invalid top-level domain\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "6c9f235c-5b9f-4d98-a927-42d94fb4844d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparison Result:\n",
      "(Row 0) Cleaned Value: None <class 'NoneType'>, Expected Value: This_is_an_intentional_false_negative <class 'str'>, \n",
      "(Row 17) Cleaned Value: None <class 'NoneType'>, Expected Value: test@[example].com <class 'str'>, \n"
     ]
    }
   ],
   "source": [
    "# Run the testing function\n",
    "result = test_cleaning_report(clean_email, df, df_report, 'dirty_email', 'expected_email')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0f378e24-fc57-4960-99ad-e586dffab7a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   dirty_dates_nulls_encountered  dirty_dates_parsing_success  \\\n",
      "0                              3                           10   \n",
      "\n",
      "   dirty_dates_parsing_failed  dirty_phonenull_values_encountered  \\\n",
      "0                           7                                   0   \n",
      "\n",
      "   dirty_phonevalid_phone_numbers  dirty_phoneinvalid_phone_numbers  \\\n",
      "0                              17                                 3   \n",
      "\n",
      "   dirty_geo_null_values_encountered  dirty_geo_leading_trailing_whitespace  \\\n",
      "0                                 15                                      1   \n",
      "\n",
      "   dirty_geo_converted_to_float  dirty_geo_ValueError --> None  ...  \\\n",
      "0                             3                              2  ...   \n",
      "\n",
      "   dirty_bool_strings_nonconverted  dirty_bool_nonstrings_nonconverted  \\\n",
      "0                                2                                   2   \n",
      "\n",
      "   dirty_email_null_values_encountered  \\\n",
      "0                                    2   \n",
      "\n",
      "   dirty_email_leading_trailing_whitespace  dirty_email_spaces_in_domain_name  \\\n",
      "0                                        1                                  3   \n",
      "\n",
      "   dirty_email_double_periods_in_domain_name  dirty_email_double_at_symbols  \\\n",
      "0                                          1                              1   \n",
      "\n",
      "   dirty_email_hyphens_in_domain_name  dirty_email_invalid_email_pattern  \\\n",
      "0                                   2                                  9   \n",
      "\n",
      "   dirty_email_valid_emails  \n",
      "0                         9  \n",
      "\n",
      "[1 rows x 34 columns]\n"
     ]
    }
   ],
   "source": [
    "df['cleaned_email'] = df['dirty_email'].apply(clean_email, df_report=df_report, dirty_column_name='dirty_email')\n",
    "print(df_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f60ea02-445f-4f8b-a2b0-c0375e844aac",
   "metadata": {
    "tags": []
   },
   "source": [
    "### email: Delete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "af295be0-4df5-4591-ab1f-63567a51a55e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a global dictionary to track cleaning actions\n",
    "#IMPORTANT: Needs to be resetted to 0, before .apply()-ing each cleaning_function in order to show valid counters\n",
    "cleaning_summary_email = {\n",
    "    \"null_values_encountered\": 0,\n",
    "    \"leading_trailing_whitespace\": 0,\n",
    "    \"spaces_in_domain_name\": 0,\n",
    "    \"double_periods_in_domain_name\": 0,\n",
    "    \"double_at_symbols\": 0,\n",
    "    \"hyphens_in_domain_name\": 0,\n",
    "    \"invalid_email_pattern\": 0,\n",
    "    \"valid_emails\": 0\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "b09ba3fd-fb0a-496f-9931-c76d75eb7e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning function for emails\n",
    "def clean_email(x):\n",
    "    #global cleaning_summary_email\n",
    "    \n",
    "    # Skip Null values\n",
    "    if pd.isna(x):\n",
    "        cleaning_summary_email[\"null_values_encountered\"] += 1\n",
    "        return None\n",
    "    \n",
    "    # Remove leading and trailing whitespace\n",
    "    original_x = x\n",
    "    x = x.strip()\n",
    "    if x != original_x:\n",
    "        cleaning_summary_email[\"leading_trailing_whitespace\"] += 1\n",
    "    \n",
    "    # Remove spaces in the domain name\n",
    "    original_x = x\n",
    "    x = re.sub(r'\\s+', '', x)\n",
    "    if x != original_x:\n",
    "        cleaning_summary_email[\"spaces_in_domain_name\"] += 1\n",
    "    \n",
    "    # Remove double periods in the domain name\n",
    "    original_x = x\n",
    "    x = re.sub(r'\\.{2,}', '.', x)\n",
    "    if x != original_x:\n",
    "        cleaning_summary_email[\"double_periods_in_domain_name\"] += 1\n",
    "    \n",
    "    # Remove double @ symbols\n",
    "    original_x = x\n",
    "    x = re.sub(r'@{2,}', '@', x)\n",
    "    if x != original_x:\n",
    "        cleaning_summary_email[\"double_at_symbols\"] += 1\n",
    "    \n",
    "    # Remove hyphens at the beginning or end of the domain name\n",
    "    original_x = x\n",
    "    x = re.sub(r'(?<!\\.)-|-(?![^.])', '', x)\n",
    "    if x != original_x:\n",
    "        cleaning_summary_email[\"hyphens_in_domain_name\"] += 1\n",
    "    \n",
    "    # Check if the email matches the basic pattern\n",
    "    if not re.match(r'^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9._-]+\\.[a-zA-Z]{2,}$', x):\n",
    "        cleaning_summary_email[\"invalid_email_pattern\"] += 1\n",
    "        return None\n",
    "    else:\n",
    "        cleaning_summary_email[\"valid_emails\"] += 1\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "21273ebd-80b6-427d-b9c8-1f7e0f4e45eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparison Result:\n",
      "(Row 16) Cleaned Value: None <class 'NoneType'>, Expected Value: test@[example].com <class 'str'>, \n",
      "False\n",
      "OrderedDict([('null_values_encountered', 2),\n",
      "             ('leading_trailing_whitespace', 1),\n",
      "             ('spaces_in_domain_name', 3),\n",
      "             ('double_periods_in_domain_name', 1),\n",
      "             ('double_at_symbols', 1),\n",
      "             ('hyphens_in_domain_name', 2),\n",
      "             ('invalid_email_pattern', 9),\n",
      "             ('valid_emails', 9)])\n"
     ]
    }
   ],
   "source": [
    "# Running the test\n",
    "result = test_cleaning(clean_email, df, 'dirty_email', 'expected_email')\n",
    "print(result)\n",
    "\n",
    "# Printing the cleaning result\n",
    "print(pprint.pformat(OrderedDict(cleaning_summary_email)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "98668329-4076-440d-be4d-04775c481949",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          dirty_phone_numbers    dirty_geo  expected_geo cleaned_geo  \\\n",
      "0           +1 (123) 456-7890    89.123456     89.123456   89.123456   \n",
      "1                123-456-7890     -91.5678           NaN        None   \n",
      "2              (111) 222 3333          xyz           NaN        None   \n",
      "3             +44 1234 567890    45.678.90           NaN        None   \n",
      "4            001-345-678-9012    -12.345      -12.345000     -12.345   \n",
      "5                    555-5555         None           NaN        None   \n",
      "6                  1234567890         None           NaN        None   \n",
      "7   +1 234 567 8901 ext. 1234         None           NaN        None   \n",
      "8        invalid_phone_number         None           NaN        None   \n",
      "9           123-456-7890 x123         None           NaN        None   \n",
      "10     234-567-8901 ext. 1234         None           NaN        None   \n",
      "11            (+1) 1234567890         None           NaN        None   \n",
      "12          +1 (1234) 567-890         None           NaN        None   \n",
      "13               1234-567-890         None           NaN        None   \n",
      "14             (123) 456-7890         None           NaN        None   \n",
      "15               123.456.7890         None           NaN        None   \n",
      "16              +123 456 7890         None           NaN        None   \n",
      "17                  123456789         None           NaN        None   \n",
      "18               +12345678901         None           NaN        None   \n",
      "19          +1 (123) 456-789A         None           NaN        None   \n",
      "\n",
      "             dirty_email        expected_email         cleaned_email  \n",
      "0   john.doe@example.com  john.doe@example.com  john.doe@example.com  \n",
      "1       jane.doe@example                  None                  None  \n",
      "2         invalid.email@                  None                  None  \n",
      "3           test@example                  None                  None  \n",
      "4              test@.com                  None                  None  \n",
      "5          test@example.                  None                  None  \n",
      "6               test@com                  None                  None  \n",
      "7           @example.com                  None                  None  \n",
      "8      test@exam ple.com      test@example.com      test@example.com  \n",
      "9      test@example .com      test@example.com      test@example.com  \n",
      "10   test @example .com       test@example.com      test@example.com  \n",
      "11     test@@example.com      test@example.com      test@example.com  \n",
      "12     test@example..com      test@example.com      test@example.com  \n",
      "13     test@-example.com      test@example.com      test@example.com  \n",
      "14     test@example-.com      test@example.com      test@example.com  \n",
      "15     test@exa_mple.com     test@exa_mple.com     test@exa_mple.com  \n",
      "16    test@[example].com    test@[example].com                  None  \n",
      "17        test@example.c                  None                  None  \n",
      "18                  None                  None                  None  \n",
      "19                  None                  None                  None  \n"
     ]
    }
   ],
   "source": [
    "# Apply the clean_email function to the dirty_email column\n",
    "df['cleaned_email'] = df['dirty_email'].apply(clean_email)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d8f2c1b-7fd2-436e-a2cc-ba7859548650",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Dealing with: Currencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "63131185-0ed4-4738-934a-6cd2b29a2ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.clean_currency import clean_currency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "006f15c9-3b82-426d-8314-7d9d7989dd85",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_dirty_and_expected_data(\n",
    "    df,\n",
    "    'dirty_payment',\n",
    "    'expected_payment',\n",
    "    [\n",
    "        'foo',\n",
    "        '$100.00',\n",
    "        '€50,00',\n",
    "        '¥5000',\n",
    "        '£75.50',\n",
    "        '1000 INR',\n",
    "        '120.75 AUD',\n",
    "        '200 CAD',\n",
    "        '20.99',\n",
    "        '25.50 USD',\n",
    "        '30.00 EUR',\n",
    "        '40 GBP',\n",
    "        '45.25 JPY',\n",
    "        '50.75 CNY'\n",
    "    ],\n",
    "    [\n",
    "        'This_is_an_intentional_false_negative',\n",
    "        '100.00 USD',\n",
    "        '50.00 EUR',\n",
    "        '5000 JPY',\n",
    "        '75.50 GBP',\n",
    "        '1000 INR',\n",
    "        '120.75 AUD',\n",
    "        '200 CAD',\n",
    "        '20.99',\n",
    "        '25.50 USD',\n",
    "        '30.00 EUR',\n",
    "        '40 GBP',\n",
    "        '45.25 JPY',\n",
    "        '50.75 CNY'\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "79e71918-2a74-4ccd-9146-8272b1be6721",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparison Result:\n",
      "(Row 0) Cleaned Value: foo <class 'str'>, Expected Value: This_is_an_intentional_false_negative <class 'str'>, \n"
     ]
    }
   ],
   "source": [
    "# Run the testing function\n",
    "result = test_cleaning_report(clean_currency, df, df_report, 'dirty_payment', 'expected_payment')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "242e2cd2-8ff7-49a4-8fc4-cb24354ea43d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   dirty_payment expected_payment cleaned_payment\n",
      "0        $100.00       100.00 USD      100.00 USD\n",
      "1         €50,00        50.00 EUR       50.00 EUR\n",
      "2          ¥5000         5000 JPY        5000 JPY\n",
      "3         £75.50        75.50 GBP       75.50 GBP\n",
      "4       1000 INR         1000 INR        1000 INR\n",
      "5     120.75 AUD       120.75 AUD      120.75 AUD\n",
      "6        200 CAD          200 CAD         200 CAD\n",
      "7          20.99            20.99           20.99\n",
      "8      25.50 USD        25.50 USD       25.50 USD\n",
      "9      30.00 EUR        30.00 EUR       30.00 EUR\n",
      "10        40 GBP           40 GBP          40 GBP\n",
      "11     45.25 JPY        45.25 JPY       45.25 JPY\n",
      "12     50.75 CNY        50.75 CNY       50.75 CNY\n",
      "13          None             None            None\n",
      "14          None             None            None\n",
      "15          None             None            None\n",
      "16          None             None            None\n",
      "17          None             None            None\n",
      "18          None             None            None\n",
      "19          None             None            None\n"
     ]
    }
   ],
   "source": [
    "df['cleaned_payment'] = df['dirty_payment'].apply(clean_payment)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "0fb6113b-a98c-41f5-93ca-78e50b7e6f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_currency(payment):\n",
    "    if pd.isna(payment):\n",
    "        return None\n",
    "    \n",
    "    # Define a regex pattern to match the currency code at the end of the payment string\n",
    "    currency_pattern = r'\\b[A-Z]{3}\\b'\n",
    "    \n",
    "    # Extract the currency code from the payment\n",
    "    match = re.search(currency_pattern, payment)\n",
    "    if match:\n",
    "        currency_code = match.group()\n",
    "    else:\n",
    "        currency_code = None\n",
    "    \n",
    "    return currency_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "1a174ed9-d66c-4212-88b9-b658a93425f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   dirty_payment expected_payment cleaned_payment currency\n",
      "0        $100.00       100.00 USD      100.00 USD      USD\n",
      "1         €50,00        50.00 EUR       50.00 EUR      EUR\n",
      "2          ¥5000         5000 JPY        5000 JPY      JPY\n",
      "3         £75.50        75.50 GBP       75.50 GBP      GBP\n",
      "4       1000 INR         1000 INR        1000 INR      INR\n",
      "5     120.75 AUD       120.75 AUD      120.75 AUD      AUD\n",
      "6        200 CAD          200 CAD         200 CAD      CAD\n",
      "7          20.99            20.99           20.99     None\n",
      "8      25.50 USD        25.50 USD       25.50 USD      USD\n",
      "9      30.00 EUR        30.00 EUR       30.00 EUR      EUR\n",
      "10        40 GBP           40 GBP          40 GBP      GBP\n",
      "11     45.25 JPY        45.25 JPY       45.25 JPY      JPY\n",
      "12     50.75 CNY        50.75 CNY       50.75 CNY      CNY\n",
      "13          None             None            None     None\n",
      "14          None             None            None     None\n",
      "15          None             None            None     None\n",
      "16          None             None            None     None\n",
      "17          None             None            None     None\n",
      "18          None             None            None     None\n",
      "19          None             None            None     None\n"
     ]
    }
   ],
   "source": [
    "df['currency'] = df['cleaned_payment'].apply(extract_currency)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "9d873ded-e71c-4824-b5a5-9261198552bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_currency_and_convert_to_float(payment):\n",
    "    if pd.isna(payment):\n",
    "        return None\n",
    "    \n",
    "    # Define a regex pattern to match the currency code at the end of the payment string\n",
    "    currency_pattern = r'\\b[A-Z]{3}\\b'\n",
    "    \n",
    "    # Remove the currency code from the payment\n",
    "    cleaned_payment = re.sub(currency_pattern, '', payment).strip()\n",
    "    \n",
    "    # Replace commas with dots (if any)\n",
    "    cleaned_payment = cleaned_payment.replace(',', '.')\n",
    "    \n",
    "    # Try to convert the cleaned payment to float\n",
    "    try:\n",
    "        cleaned_payment_float = float(cleaned_payment)\n",
    "    except ValueError:\n",
    "        # Return None if conversion fails\n",
    "        cleaned_payment_float = None\n",
    "    \n",
    "    return cleaned_payment_float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "8664628c-30f5-4f00-b861-bcfbaf2f1022",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   dirty_payment expected_payment cleaned_payment currency  \\\n",
      "0        $100.00       100.00 USD      100.00 USD      USD   \n",
      "1         €50,00        50.00 EUR       50.00 EUR      EUR   \n",
      "2          ¥5000         5000 JPY        5000 JPY      JPY   \n",
      "3         £75.50        75.50 GBP       75.50 GBP      GBP   \n",
      "4       1000 INR         1000 INR        1000 INR      INR   \n",
      "5     120.75 AUD       120.75 AUD      120.75 AUD      AUD   \n",
      "6        200 CAD          200 CAD         200 CAD      CAD   \n",
      "7          20.99            20.99           20.99     None   \n",
      "8      25.50 USD        25.50 USD       25.50 USD      USD   \n",
      "9      30.00 EUR        30.00 EUR       30.00 EUR      EUR   \n",
      "10        40 GBP           40 GBP          40 GBP      GBP   \n",
      "11     45.25 JPY        45.25 JPY       45.25 JPY      JPY   \n",
      "12     50.75 CNY        50.75 CNY       50.75 CNY      CNY   \n",
      "13          None             None            None     None   \n",
      "14          None             None            None     None   \n",
      "15          None             None            None     None   \n",
      "16          None             None            None     None   \n",
      "17          None             None            None     None   \n",
      "18          None             None            None     None   \n",
      "19          None             None            None     None   \n",
      "\n",
      "    cleaned_payment_float  \n",
      "0                  100.00  \n",
      "1                   50.00  \n",
      "2                 5000.00  \n",
      "3                   75.50  \n",
      "4                 1000.00  \n",
      "5                  120.75  \n",
      "6                  200.00  \n",
      "7                   20.99  \n",
      "8                   25.50  \n",
      "9                   30.00  \n",
      "10                  40.00  \n",
      "11                  45.25  \n",
      "12                  50.75  \n",
      "13                    NaN  \n",
      "14                    NaN  \n",
      "15                    NaN  \n",
      "16                    NaN  \n",
      "17                    NaN  \n",
      "18                    NaN  \n",
      "19                    NaN  \n"
     ]
    }
   ],
   "source": [
    "df['cleaned_payment_float'] = df['cleaned_payment'].apply(remove_currency_and_convert_to_float)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "13116c47-5880-47ce-be86-91f4e6ced9e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparison Result:\n",
      "OrderedDict([('null_values_encountered', 28),\n",
      "             ('leading_trailing_whitespace', 0),\n",
      "             ('commas_replaced', 4),\n",
      "             ('currency_symbol_replaced', 16)])\n"
     ]
    }
   ],
   "source": [
    "result = test_cleaning(clean_payment, df, 'dirty_payment', 'expected_payment')\n",
    "\n",
    "# Printing the cleaning result\n",
    "print(pprint.pformat(OrderedDict(cleaning_summary_currency)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "7ccb20b7-e185-491e-a6ef-fb3eb77bd6e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate test-case for currency extraction.\n",
    "# We slighly misuse the create_dirty_and_expected_data function, we create 2 expected result\n",
    "\n",
    "create_dirty_and_expected_data(\n",
    "    df,\n",
    "    'expected_currency',\n",
    "    'expected_payment_float',\n",
    "    [\n",
    "        'foo',\n",
    "        'USD',\n",
    "        'EUR',\n",
    "        'JPY',\n",
    "        'GBP',\n",
    "        'INR',\n",
    "        'AUD',\n",
    "        'CAD',\n",
    "        None,\n",
    "        'USD',\n",
    "        'EUR',\n",
    "        'GBP',\n",
    "        'JPY',\n",
    "        'CNY'\n",
    "    ],\n",
    "    [\n",
    "        'This_is_an_intentional_false_negative',\n",
    "        100,\n",
    "        50.00,\n",
    "        5000,\n",
    "        75.50,\n",
    "        1000,\n",
    "        120.75,\n",
    "        200,\n",
    "        20.99,\n",
    "        25.50,\n",
    "        30.00,\n",
    "        40,\n",
    "        45.25,\n",
    "        50.75\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "eff0533c-c9cf-44a8-a5d9-59ef2e4520ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparison Result:\n"
     ]
    }
   ],
   "source": [
    "result = test_cleaning(extract_currency, df, 'cleaned_payment', 'expected_currency')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "bf109e03-4da0-4dde-97ee-706bb97f4516",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparison Result:\n",
      "(Row 13) Cleaned Value: nan <class 'float'>, Expected Value: nan <class 'float'>, \n",
      "(Row 14) Cleaned Value: nan <class 'float'>, Expected Value: nan <class 'float'>, \n",
      "(Row 15) Cleaned Value: nan <class 'float'>, Expected Value: nan <class 'float'>, \n",
      "(Row 16) Cleaned Value: nan <class 'float'>, Expected Value: nan <class 'float'>, \n",
      "(Row 17) Cleaned Value: nan <class 'float'>, Expected Value: nan <class 'float'>, \n",
      "(Row 18) Cleaned Value: nan <class 'float'>, Expected Value: nan <class 'float'>, \n",
      "(Row 19) Cleaned Value: nan <class 'float'>, Expected Value: nan <class 'float'>, \n"
     ]
    }
   ],
   "source": [
    "result = test_cleaning(remove_currency_and_convert_to_float, df, 'cleaned_payment', 'expected_payment_float')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "431c7b10-cc92-4fa7-b326-92a8dc42b540",
   "metadata": {},
   "source": [
    "## Dealing with: Boolean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6b8b0d09-323c-48a9-a5b6-8c39ddd994e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.clean_boolean import clean_boolean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0a3de55f-5370-4f4a-8b86-a5661548b804",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_dirty_and_expected_data(\n",
    "    df,\n",
    "    'dirty_bool',\n",
    "    'expected_bool',\n",
    "    [\n",
    "        'foo',\n",
    "        '1',\n",
    "        '0',\n",
    "        'yes',\n",
    "        'YES',\n",
    "        'y',\n",
    "        'Y',\n",
    "        'true',\n",
    "        'TRUE',\n",
    "        'True',\n",
    "        'false',\n",
    "        'FALSE',\n",
    "        'False',\n",
    "        'no',\n",
    "        'NO',\n",
    "        'No',\n",
    "        'n',\n",
    "        'N',\n",
    "        'a',\n",
    "        3\n",
    "    ],\n",
    "    [\n",
    "        'This_is_an_intentional_false_negative',\n",
    "        True,\n",
    "        False,\n",
    "        True,\n",
    "        True,\n",
    "        True,\n",
    "        True,\n",
    "        True,\n",
    "        True,\n",
    "        True,\n",
    "        False,\n",
    "        False,\n",
    "        False,\n",
    "        False,\n",
    "        False,\n",
    "        False,\n",
    "        False,\n",
    "        False,\n",
    "        None,\n",
    "        None\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f936b734-aee1-4faa-8bf3-72c2ea93da8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparison Result:\n",
      "(Row 0) Cleaned Value: None <class 'NoneType'>, Expected Value: This_is_an_intentional_false_negative <class 'str'>, \n"
     ]
    }
   ],
   "source": [
    "# Run the testing function\n",
    "result = test_cleaning_report(clean_boolean, df, df_report, 'dirty_bool', 'expected_bool')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d03c355c-da18-4022-b1a1-96f3bdc7d935",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   dirty_dates_nulls_encountered  dirty_dates_parsing_success  \\\n",
      "0                              3                           10   \n",
      "\n",
      "   dirty_dates_parsing_failed  dirty_phonenull_values_encountered  \\\n",
      "0                           7                                   0   \n",
      "\n",
      "   dirty_phonevalid_phone_numbers  dirty_phoneinvalid_phone_numbers  \\\n",
      "0                              17                                 3   \n",
      "\n",
      "   dirty_geo_null_values_encountered  dirty_geo_leading_trailing_whitespace  \\\n",
      "0                                 15                                      1   \n",
      "\n",
      "   dirty_geo_converted_to_float  dirty_geo_ValueError --> None  ...  \\\n",
      "0                             3                              2  ...   \n",
      "\n",
      "   dirty_emaildouble_at_symbols  dirty_emailhyphens_in_domain_name  \\\n",
      "0                             2                                  2   \n",
      "\n",
      "   dirty_emailinvalid_email_pattern  dirty_emailvalid_emails  \\\n",
      "0                                16                       15   \n",
      "\n",
      "   dirty_bool_nulls_encountered  dirty_bool_natural_bools_untouched  \\\n",
      "0                             0                                   0   \n",
      "\n",
      "   dirty_bool_truelike_converted  dirty_bool_falselike_converted  \\\n",
      "0                             18                              18   \n",
      "\n",
      "   dirty_bool_strings_nonconverted  dirty_bool_nonstrings_nonconverted  \n",
      "0                                2                                   2  \n",
      "\n",
      "[1 rows x 26 columns]\n"
     ]
    }
   ],
   "source": [
    "# Running the actual cleaning\n",
    "df['cleaned_bool'] = df['dirty_bool'].apply(clean_boolean, df_report=df_report, dirty_column_name='dirty_bool')\n",
    "print(df_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cd1019b-f113-47c3-b49e-5e2373224928",
   "metadata": {},
   "source": [
    "## Cleaning survey salary data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2848d3dd-260d-453b-b0c5-cbfd79c39201",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.clean_salary import clean_salary, clean_salary_og"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1cacb635-e5fb-4190-9a50-c1c06ff94140",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[1;31mSignature:\u001b[0m   \u001b[0mclean_salary_og\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf_report\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprefix\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
       "\u001b[1;31mSource:\u001b[0m   \n",
       "\u001b[1;32mdef\u001b[0m \u001b[0mclean_salary_og\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf_report\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprefix\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[1;34m\"\"\" A cleaning function for salary with reporting. \n",
       "    Fills an empty df (df_report) with statistics of what modifications this function made.\n",
       "    Keeps track of which column the statistics was gathered from (prefix).\n",
       "    Usage example: df['cleaned_salary'] = df['dirty_salary'].apply(clean_salary, df_report=df_report, prefix='mydf_dirty_salary')\n",
       "    \n",
       "    Tip: Should be used before pd.to_numeric()\n",
       "    Tip: Handling none-s should be done separately, this function skips nones.\n",
       "    \"\"\"\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[1;31m# Initialize columns if they don't exist\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mcolumns_to_initialize\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[0mprefix\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'_null_values_encountered'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[0mprefix\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'_strings_encountered'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[0mprefix\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'_leading_trailing_whitespace'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[0mprefix\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'_commas_replaced'\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[1;33m]\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[1;32mfor\u001b[0m \u001b[0mcolumn\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcolumns_to_initialize\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[1;32mif\u001b[0m \u001b[0mcolumn\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdf_report\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
       "\u001b[0m            \u001b[0mdf_report\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcolumn\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\n",
       "\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[1;31m# Increment appropriate counters based on the value of x\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[1;32mif\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# Skip Null values\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[0mdf_report\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mat\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprefix\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'_null_values_encountered'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[1;32mreturn\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\n",
       "\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[1;31m# Check for strings\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[0mdf_report\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mat\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprefix\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'_strings_encountered'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[1;33m\n",
       "\u001b[0m        \u001b[1;31m# Remove leading and trailing whitespace\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[0moriginal_x\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0moriginal_x\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
       "\u001b[0m            \u001b[0mdf_report\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mat\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprefix\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'_leading_trailing_whitespace'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\n",
       "\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[1;31m# Replace commas with dots. \u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[1;31m# pd.to_numeric function can correctly identify '.' as decimal separators, but not ','\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[0moriginal_x\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m','\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'.'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0moriginal_x\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
       "\u001b[0m            \u001b[0mdf_report\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mat\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprefix\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'_commas_replaced'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[1;32mreturn\u001b[0m \u001b[0mx\u001b[0m  \u001b[1;31m# Return the cleaned string\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[1;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
       "\u001b[1;31mFile:\u001b[0m      e:\\_programming\\_dataanalysis\\salary_data_combined\\scripts\\clean_salary.py\n",
       "\u001b[1;31mType:\u001b[0m      function\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "??  clean_salary_og"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1ee73a28-cdd3-4b9c-a69f-001817e23148",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_salary = pd.DataFrame(index=range(10))\n",
    "df_salary_report = pd.DataFrame(index=[0])\n",
    "\n",
    "# Creating uncleaned data and the expected data, to test our cleaning function\n",
    "create_dirty_and_expected_data(\n",
    "    df_salary,\n",
    "    'salary',\n",
    "    'expected_salary_1',\n",
    "    [\n",
    "        'foo',\n",
    "        '1',\n",
    "        1,\n",
    "        '$1',\n",
    "        '>1',\n",
    "        'one',\n",
    "        ' 1',\n",
    "        '1,0',\n",
    "        '1.0'\n",
    "    ],\n",
    "    [\n",
    "        'foo',\n",
    "        '1',\n",
    "        1,\n",
    "        '$1',\n",
    "        '>1',\n",
    "        'one',\n",
    "        '1',\n",
    "        '1.0',\n",
    "        '1.0'\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2119d2f8-a388-45d9-b982-ba2ccef6b083",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The truth value of a DataFrame is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_6068\\2044986413.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf_salary\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'converted_salary_1'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf_salary\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'salary'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclean_salary\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdf_salary_report\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'dirty_salary'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_salary\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\myNewEnv\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36mapply\u001b[1;34m(self, func, convert_dtype, args, **kwargs)\u001b[0m\n\u001b[0;32m   4769\u001b[0m         \u001b[0mdtype\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mfloat64\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4770\u001b[0m         \"\"\"\n\u001b[1;32m-> 4771\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mSeriesApply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconvert_dtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4772\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4773\u001b[0m     def _reduce(\n",
      "\u001b[1;32m~\\anaconda3\\envs\\myNewEnv\\lib\\site-packages\\pandas\\core\\apply.py\u001b[0m in \u001b[0;36mapply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1121\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1122\u001b[0m         \u001b[1;31m# self.f is Callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1123\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_standard\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1124\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1125\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0magg\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\myNewEnv\\lib\\site-packages\\pandas\\core\\apply.py\u001b[0m in \u001b[0;36mapply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1172\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1173\u001b[0m                 \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1174\u001b[1;33m                 mapped = lib.map_infer(\n\u001b[0m\u001b[0;32m   1175\u001b[0m                     \u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1176\u001b[0m                     \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\myNewEnv\\lib\\site-packages\\pandas\\_libs\\lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\myNewEnv\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m__nonzero__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1525\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mfinal\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1526\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__nonzero__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mNoReturn\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1527\u001b[1;33m         raise ValueError(\n\u001b[0m\u001b[0;32m   1528\u001b[0m             \u001b[1;34mf\"The truth value of a {type(self).__name__} is ambiguous. \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1529\u001b[0m             \u001b[1;34m\"Use a.empty, a.bool(), a.item(), a.any() or a.all().\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: The truth value of a DataFrame is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all()."
     ]
    }
   ],
   "source": [
    "df_salary['converted_salary_1'] = df_salary['salary'].apply(clean_salary,df_salary_report,'dirty_salary')\n",
    "print(df_salary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "cb344754-cd26-4162-b54c-e22386b1a9e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: [0]\n"
     ]
    }
   ],
   "source": [
    "print(df_salary_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2effda45-cdc5-4788-abcd-1600d2689104",
   "metadata": {},
   "source": [
    "### removing special characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "60d4d7cc-8796-44f8-908d-bfef6f834efa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Viktor\\AppData\\Local\\Temp\\ipykernel_8516\\3893120812.py:1: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
      "  df_salary['salary_2'] = df_salary['salary'].str.replace('$', '')\n"
     ]
    }
   ],
   "source": [
    "df_salary['salary_2'] = df_salary['salary'].str.replace('$', '')\n",
    "df_salary['salary_2'] = df_salary['salary'].str.replace('> ', '')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da7ee3af-e175-4bdb-9dbd-2e3adc8d8fce",
   "metadata": {},
   "source": [
    "### pd.to_numeric()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a9344c5f-0c17-4610-bbca-a0c8af5255a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#salary_2 = converted_salary_1\n",
    "\n",
    "# Creating uncleaned data and the expected data, to test our cleaning function\n",
    "create_dirty_and_expected_data(\n",
    "    df_salary,\n",
    "    'salary_2',\n",
    "    'expected_salary_2',\n",
    "    [\n",
    "        'foo',\n",
    "        1,\n",
    "        '1',\n",
    "        '$1',\n",
    "        '>1'\n",
    "        'one',\n",
    "        '1',\n",
    "        '1.0',\n",
    "        '1.0'\n",
    "    ],\n",
    "    [\n",
    "        None,\n",
    "        1,\n",
    "        1,\n",
    "        1,\n",
    "        1,\n",
    "        None,\n",
    "        1,\n",
    "        1,\n",
    "        1\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1496c764-3c82-4c5d-954d-b31d801e4cf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  salary expected_salary_1 salary_2  expected_salary_2  converted_salary  \\\n",
      "0    foo               foo      foo                NaN               NaN   \n",
      "1      1                 1        1                1.0               1.0   \n",
      "2      1                 1        1                1.0               1.0   \n",
      "3     $1                $1       $1                1.0               NaN   \n",
      "4     >1                >1    >1one                1.0               NaN   \n",
      "5    one               one        1                NaN               NaN   \n",
      "6      1                 1      1.0                1.0               1.0   \n",
      "7    1,0               1.0      1.0                1.0               NaN   \n",
      "8    1.0               1.0     None                1.0               1.0   \n",
      "9   None              None     None                NaN               NaN   \n",
      "\n",
      "   to_numeric_coerce  \n",
      "0                NaN  \n",
      "1                1.0  \n",
      "2                1.0  \n",
      "3                NaN  \n",
      "4                NaN  \n",
      "5                NaN  \n",
      "6                1.0  \n",
      "7                NaN  \n",
      "8                1.0  \n",
      "9                NaN  \n"
     ]
    }
   ],
   "source": [
    "df_salary['to_numeric_coerce'] = df_salary['salary'].apply(pd.to_numeric, errors='coerce')\n",
    "print(df_salary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a8924768-ad94-463f-9ff3-c0e5df62c819",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Unable to parse string \"foo\" at position 0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\anaconda3\\envs\\myNewEnv\\lib\\site-packages\\pandas\\_libs\\lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.maybe_convert_numeric\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Unable to parse string \"foo\"",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_6068\\2358160721.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf_salary\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'to_numeric_raise'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf_salary\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'salary'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_numeric\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'raise'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_salary\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\myNewEnv\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36mapply\u001b[1;34m(self, func, convert_dtype, args, **kwargs)\u001b[0m\n\u001b[0;32m   4769\u001b[0m         \u001b[0mdtype\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mfloat64\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4770\u001b[0m         \"\"\"\n\u001b[1;32m-> 4771\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mSeriesApply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconvert_dtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4772\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4773\u001b[0m     def _reduce(\n",
      "\u001b[1;32m~\\anaconda3\\envs\\myNewEnv\\lib\\site-packages\\pandas\\core\\apply.py\u001b[0m in \u001b[0;36mapply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1121\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1122\u001b[0m         \u001b[1;31m# self.f is Callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1123\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_standard\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1124\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1125\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0magg\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\myNewEnv\\lib\\site-packages\\pandas\\core\\apply.py\u001b[0m in \u001b[0;36mapply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1172\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1173\u001b[0m                 \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1174\u001b[1;33m                 mapped = lib.map_infer(\n\u001b[0m\u001b[0;32m   1175\u001b[0m                     \u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1176\u001b[0m                     \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\myNewEnv\\lib\\site-packages\\pandas\\_libs\\lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\myNewEnv\\lib\\site-packages\\pandas\\core\\apply.py\u001b[0m in \u001b[0;36mf\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m    140\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    141\u001b[0m             \u001b[1;32mdef\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 142\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    143\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    144\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\myNewEnv\\lib\\site-packages\\pandas\\core\\tools\\numeric.py\u001b[0m in \u001b[0;36mto_numeric\u001b[1;34m(arg, errors, downcast)\u001b[0m\n\u001b[0;32m    183\u001b[0m         \u001b[0mcoerce_numeric\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0merrors\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\"ignore\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"raise\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    184\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 185\u001b[1;33m             values, _ = lib.maybe_convert_numeric(\n\u001b[0m\u001b[0;32m    186\u001b[0m                 \u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcoerce_numeric\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcoerce_numeric\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    187\u001b[0m             )\n",
      "\u001b[1;32m~\\anaconda3\\envs\\myNewEnv\\lib\\site-packages\\pandas\\_libs\\lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.maybe_convert_numeric\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Unable to parse string \"foo\" at position 0"
     ]
    }
   ],
   "source": [
    "df_salary['to_numeric_raise'] = df_salary['salary'].apply(pd.to_numeric, errors='raise')\n",
    "print(df_salary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c44435a8-e27c-4ed6-8785-95434374b642",
   "metadata": {},
   "source": [
    "### Filling Nulls with 0."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af4a3992-d9ec-4560-ba77-3d68bd090956",
   "metadata": {},
   "source": [
    "# The .info() function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4b51f2e5-6799-4951-a0ae-db0346aefef1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5 entries, 0 to 4\n",
      "Data columns (total 3 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   integers  5 non-null      int64  \n",
      " 1   mixed     5 non-null      object \n",
      " 2   withnull  4 non-null      float64\n",
      "dtypes: float64(1), int64(1), object(1)\n",
      "memory usage: 248.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "data = {\n",
    "    'integers': [1, 2, 3, 4, 5],\n",
    "    'mixed': [1, 2, 'a', 4, 5],\n",
    "    'withnull': [1, 2, None, 4, 5]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ab70d662-4ce2-45e7-8d12-0412a576bde0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1\n",
       "1    2\n",
       "2    3\n",
       "3    4\n",
       "4    5\n",
       "Name: integers, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['integers'].astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "660b71c4-7b76-496d-9b7f-a6383573ad4c",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "invalid literal for int() with base 10: 'a'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_6068\\8349942.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'mixed'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'int64'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\envs\\myNewEnv\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mastype\u001b[1;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[0;32m   6238\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6239\u001b[0m             \u001b[1;31m# else, only a single dtype is given\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 6240\u001b[1;33m             \u001b[0mnew_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_mgr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   6241\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_constructor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__finalize__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"astype\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6242\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\myNewEnv\\lib\\site-packages\\pandas\\core\\internals\\managers.py\u001b[0m in \u001b[0;36mastype\u001b[1;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[0;32m    446\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    447\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"raise\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mT\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 448\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"astype\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    449\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    450\u001b[0m     def convert(\n",
      "\u001b[1;32m~\\anaconda3\\envs\\myNewEnv\\lib\\site-packages\\pandas\\core\\internals\\managers.py\u001b[0m in \u001b[0;36mapply\u001b[1;34m(self, f, align_keys, ignore_failures, **kwargs)\u001b[0m\n\u001b[0;32m    350\u001b[0m                     \u001b[0mapplied\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    351\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 352\u001b[1;33m                     \u001b[0mapplied\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    353\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    354\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mignore_failures\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\myNewEnv\\lib\\site-packages\\pandas\\core\\internals\\blocks.py\u001b[0m in \u001b[0;36mastype\u001b[1;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[0;32m    524\u001b[0m         \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    525\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 526\u001b[1;33m         \u001b[0mnew_values\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mastype_array_safe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    527\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    528\u001b[0m         \u001b[0mnew_values\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmaybe_coerce_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew_values\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\myNewEnv\\lib\\site-packages\\pandas\\core\\dtypes\\astype.py\u001b[0m in \u001b[0;36mastype_array_safe\u001b[1;34m(values, dtype, copy, errors)\u001b[0m\n\u001b[0;32m    297\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    298\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 299\u001b[1;33m         \u001b[0mnew_values\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mastype_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    300\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mValueError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    301\u001b[0m         \u001b[1;31m# e.g. astype_nansafe can fail on object-dtype of strings\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\myNewEnv\\lib\\site-packages\\pandas\\core\\dtypes\\astype.py\u001b[0m in \u001b[0;36mastype_array\u001b[1;34m(values, dtype, copy)\u001b[0m\n\u001b[0;32m    228\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    229\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 230\u001b[1;33m         \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mastype_nansafe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    231\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    232\u001b[0m     \u001b[1;31m# in pandas we don't store numpy str dtypes, so convert to object\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\myNewEnv\\lib\\site-packages\\pandas\\core\\dtypes\\astype.py\u001b[0m in \u001b[0;36mastype_nansafe\u001b[1;34m(arr, dtype, copy, skipna)\u001b[0m\n\u001b[0;32m    168\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcopy\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mis_object_dtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mis_object_dtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    169\u001b[0m         \u001b[1;31m# Explicit copy, or required since NumPy can't view from / to object.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 170\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0marr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    171\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    172\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0marr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: invalid literal for int() with base 10: 'a'"
     ]
    }
   ],
   "source": [
    "df['mixed'].astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ac7d4ad0-465b-4197-9a15-3bf20fb65f39",
   "metadata": {},
   "outputs": [
    {
     "ename": "IntCastingNaNError",
     "evalue": "Cannot convert non-finite values (NA or inf) to integer",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIntCastingNaNError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_6068\\2381860459.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'withnull'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'int64'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\envs\\myNewEnv\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mastype\u001b[1;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[0;32m   6238\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6239\u001b[0m             \u001b[1;31m# else, only a single dtype is given\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 6240\u001b[1;33m             \u001b[0mnew_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_mgr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   6241\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_constructor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__finalize__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"astype\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6242\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\myNewEnv\\lib\\site-packages\\pandas\\core\\internals\\managers.py\u001b[0m in \u001b[0;36mastype\u001b[1;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[0;32m    446\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    447\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"raise\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mT\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 448\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"astype\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    449\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    450\u001b[0m     def convert(\n",
      "\u001b[1;32m~\\anaconda3\\envs\\myNewEnv\\lib\\site-packages\\pandas\\core\\internals\\managers.py\u001b[0m in \u001b[0;36mapply\u001b[1;34m(self, f, align_keys, ignore_failures, **kwargs)\u001b[0m\n\u001b[0;32m    350\u001b[0m                     \u001b[0mapplied\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    351\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 352\u001b[1;33m                     \u001b[0mapplied\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    353\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    354\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mignore_failures\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\myNewEnv\\lib\\site-packages\\pandas\\core\\internals\\blocks.py\u001b[0m in \u001b[0;36mastype\u001b[1;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[0;32m    524\u001b[0m         \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    525\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 526\u001b[1;33m         \u001b[0mnew_values\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mastype_array_safe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    527\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    528\u001b[0m         \u001b[0mnew_values\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmaybe_coerce_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew_values\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\myNewEnv\\lib\\site-packages\\pandas\\core\\dtypes\\astype.py\u001b[0m in \u001b[0;36mastype_array_safe\u001b[1;34m(values, dtype, copy, errors)\u001b[0m\n\u001b[0;32m    297\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    298\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 299\u001b[1;33m         \u001b[0mnew_values\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mastype_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    300\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mValueError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    301\u001b[0m         \u001b[1;31m# e.g. astype_nansafe can fail on object-dtype of strings\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\myNewEnv\\lib\\site-packages\\pandas\\core\\dtypes\\astype.py\u001b[0m in \u001b[0;36mastype_array\u001b[1;34m(values, dtype, copy)\u001b[0m\n\u001b[0;32m    228\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    229\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 230\u001b[1;33m         \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mastype_nansafe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    231\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    232\u001b[0m     \u001b[1;31m# in pandas we don't store numpy str dtypes, so convert to object\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\myNewEnv\\lib\\site-packages\\pandas\\core\\dtypes\\astype.py\u001b[0m in \u001b[0;36mastype_nansafe\u001b[1;34m(arr, dtype, copy, skipna)\u001b[0m\n\u001b[0;32m    138\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    139\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0missubdtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloating\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mis_integer_dtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 140\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_astype_float_to_int_nansafe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    141\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    142\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mis_object_dtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\myNewEnv\\lib\\site-packages\\pandas\\core\\dtypes\\astype.py\u001b[0m in \u001b[0;36m_astype_float_to_int_nansafe\u001b[1;34m(values, dtype, copy)\u001b[0m\n\u001b[0;32m    180\u001b[0m     \"\"\"\n\u001b[0;32m    181\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misfinite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 182\u001b[1;33m         raise IntCastingNaNError(\n\u001b[0m\u001b[0;32m    183\u001b[0m             \u001b[1;34m\"Cannot convert non-finite values (NA or inf) to integer\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    184\u001b[0m         )\n",
      "\u001b[1;31mIntCastingNaNError\u001b[0m: Cannot convert non-finite values (NA or inf) to integer"
     ]
    }
   ],
   "source": [
    "df['withnull'].astype('int64')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72460144-6596-43ec-834e-0c03c9f3ab2a",
   "metadata": {},
   "source": [
    "# Null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7733623c-e676-4e62-860f-e04933fba549",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non-finite values:\n",
      "   salary_eur\n",
      "3         NaN\n",
      "6         inf\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Sample DataFrame\n",
    "data = {\n",
    "    'salary_eur': [64000.0, 55000.0, 70000.0, None, 63000.0, 66000.0, float('inf'), 72000.0, 68000.0, 100000.0]\n",
    "}\n",
    "df_salary_conversion = pd.DataFrame(data)\n",
    "\n",
    "# Drop NaN values from 'salary_eur' and assign back to the DataFrame\n",
    "df_salary_conversion['salary_eur'].dropna(inplace=True)\n",
    "\n",
    "# Check for non-finite values after dropping NaN\n",
    "non_finite_values = df_salary_conversion[~df_salary_conversion['salary_eur'].apply(lambda x: pd.notnull(x) and np.isfinite(x))]\n",
    "print(\"Non-finite values:\")\n",
    "print(non_finite_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "57fb08fb-37d0-4313-a0f3-a3d2be6ca0af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original DataFrame:\n",
      "     A    B     C\n",
      "0  1.0  5.0   foo\n",
      "1  2.0  6.0   bar\n",
      "2  NaN  NaN  None\n",
      "3  4.0  NaN   NaN\n",
      "4  NaN  9.0   baz\n",
      "\n",
      "Boolean mask for missing values:\n",
      "       A      B      C\n",
      "0  False  False  False\n",
      "1  False  False  False\n",
      "2   True   True   True\n",
      "3  False   True   True\n",
      "4   True  False  False\n",
      "\n",
      "DataFrame after dropping rows with any NaN values:\n",
      "     A    B    C\n",
      "0  1.0  5.0  foo\n",
      "1  2.0  6.0  bar\n",
      "\n",
      "DataFrame after dropping columns with any NaN values:\n",
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: [0, 1, 2, 3, 4]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Create a DataFrame with various types of missing values\n",
    "data = {\n",
    "    'A': [1, 2, None, 4, np.nan],\n",
    "    'B': [5.0, 6.0, np.nan, None, 9.0],\n",
    "    'C': ['foo', 'bar', None, np.nan, 'baz']\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "print(\"Original DataFrame:\")\n",
    "print(df)\n",
    "print()\n",
    "\n",
    "# Using .isna() to check for missing values\n",
    "print(\"Boolean mask for missing values:\")\n",
    "print(df.isna())\n",
    "print()\n",
    "\n",
    "# Using .dropna() to drop rows with missing values\n",
    "cleaned_df = df.dropna()\n",
    "print(\"DataFrame after dropping rows with any NaN values:\")\n",
    "print(cleaned_df)\n",
    "print()\n",
    "\n",
    "# Customizing .dropna() to drop columns with missing values\n",
    "cleaned_columns_df = df.dropna(axis=1)\n",
    "print(\"DataFrame after dropping columns with any NaN values:\")\n",
    "print(cleaned_columns_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c51be6a5-1abf-4197-a4b9-ae83abe931cb",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_it18_u' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_6068\\1335480294.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#Correct way of dropping None\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mdf_it18_u\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf_it18_u\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdropna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'salary_eur'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'df_it18_u' is not defined"
     ]
    }
   ],
   "source": [
    "#Correct way of dropping None\n",
    "\n",
    "df_it18_u = df_it18_u.dropna(subset=['salary_eur'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcf243d4-a0a8-4d24-a797-290388865584",
   "metadata": {},
   "source": [
    "# Searching function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ba01afa-6840-4107-9cf5-32f67c1b511b",
   "metadata": {},
   "source": [
    "## Single keyword search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e5e8eadc-14fb-440f-81c2-9586be0ab6d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the function\n",
    "from scripts.search_keyword import search_single_keyword, search_double_keyword"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5683cf91-f3b4-4c97-9bbb-efa859424f88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[1;31mSignature:\u001b[0m  \u001b[0msearch_single_keyword\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msearch_column\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_column\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeyword\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey_value\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
       "\u001b[1;31mSource:\u001b[0m   \n",
       "\u001b[1;32mdef\u001b[0m \u001b[0msearch_single_keyword\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msearch_column\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_column\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeyword\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey_value\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[1;34m\"\"\"\n",
       "    Searches for keywords in a specified column and fills a new column with a key-value pair where there is a match.\n",
       "\n",
       "    Parameters:\n",
       "    df (pd.DataFrame): The dataframe to operate on.\n",
       "    search_column (str): The name of the column to search the keywords in.\n",
       "    new_column (str): The name of the new column to insert the key-value pair into.\n",
       "    keyword (str): A keyword to search for.\n",
       "    key_value (str): The value to insert into the new column where a keyword match is found.\n",
       "\n",
       "    Returns:\n",
       "    pd.DataFrame: The modified dataframe with the new column added.\n",
       "    \"\"\"\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mkeyword\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkeyword\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[1;33m\n",
       "\u001b[0m    \u001b[1;31m# Create the new column with the key_value where the pattern matches, else NaN\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnew_column\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0msearch_column\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mkey_value\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnotnull\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mkeyword\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[1;33m\n",
       "\u001b[0m    \u001b[1;32mreturn\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
       "\u001b[1;31mFile:\u001b[0m      e:\\_programming\\_dataanalysis\\salary_data_combined\\scripts\\search_keyword.py\n",
       "\u001b[1;31mType:\u001b[0m      function\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "?? search_single_keyword"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fcb1b82d-1a96-485b-8dbe-d8c1b38264f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_search = pd.DataFrame(index=range(10))\n",
    "\n",
    "# Creating uncleaned data and the expected data, to test our cleaning function\n",
    "create_dirty_and_expected_data(\n",
    "    df_search,\n",
    "    'job_title',\n",
    "    'expected_job_category',\n",
    "    [\n",
    "        'foo',\n",
    "        'Quality Engineer',\n",
    "        'Quality Maintenance Developer',\n",
    "        'Quality Development Maintaner',\n",
    "        'qquality'\n",
    "    ],\n",
    "    [\n",
    "        None,\n",
    "        'Q',\n",
    "        'Q',\n",
    "        'Q',\n",
    "        'Q'\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7e3962e8-7997-49ce-9843-6a8f6b1eac75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       job_title expected_job_category job_category\n",
      "0                            foo                  None         None\n",
      "1               Quality Engineer                     Q            Q\n",
      "2  Quality Maintenance Developer                     Q            Q\n",
      "3  Quality Development Maintaner                     Q            Q\n",
      "4                       qquality                     Q            Q\n",
      "5                           None                  None         None\n",
      "6                           None                  None         None\n",
      "7                           None                  None         None\n",
      "8                           None                  None         None\n",
      "9                           None                  None         None\n"
     ]
    }
   ],
   "source": [
    "df = search_single_keyword(df_search, 'job_title', 'job_category', 'quality', 'Q')\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "362b1b38-0230-4a83-86b2-952ac4904f47",
   "metadata": {},
   "source": [
    "## Double keyword search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "79bb0fdf-2379-4747-9a81-082ee9c49869",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[1;31mSignature:\u001b[0m\n",
       " \u001b[0msearch_double_keyword\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mdf\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0msearch_column\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mnew_column\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mkeyword1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mkeyword2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mkey_value\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
       "\u001b[1;31mSource:\u001b[0m   \n",
       "\u001b[1;32mdef\u001b[0m \u001b[0msearch_double_keyword\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msearch_column\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_column\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeyword1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeyword2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey_value\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[1;34m\"\"\"\n",
       "    Searches for two keywords in a specified column and fills a new column with a key-value pair where both keywords are present.\n",
       "\n",
       "    Parameters:\n",
       "    df (pd.DataFrame): The dataframe to operate on.\n",
       "    search_column (str): The name of the column to search the keywords in.\n",
       "    new_column (str): The name of the new column to insert the key-value pair into.\n",
       "    keyword1 (str): The first keyword to search for.\n",
       "    keyword2 (str): The second keyword to search for.\n",
       "    key_value (str): The value to insert into the new column where both keyword matches are found.\n",
       "\n",
       "    Returns:\n",
       "    pd.DataFrame: The modified dataframe with the new column added.\n",
       "    \"\"\"\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[1;31m# Convert keywords to lowercase for case-insensitive comparison\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mkeyword1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkeyword1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mkeyword2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkeyword2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[1;33m\n",
       "\u001b[0m    \u001b[1;31m# Create the new column with the key_value where both keywords are present, else NaN\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnew_column\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0msearch_column\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mkey_value\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnotnull\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mkeyword1\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mkeyword2\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[1;33m)\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[1;33m\n",
       "\u001b[0m    \u001b[1;32mreturn\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
       "\u001b[1;31mFile:\u001b[0m      e:\\_programming\\_dataanalysis\\salary_data_combined\\scripts\\search_keyword.py\n",
       "\u001b[1;31mType:\u001b[0m      function\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "?? search_double_keyword"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fd51df0e-d7b1-4bb6-bea6-8bc1c41ed53e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_search = pd.DataFrame(index=range(10))\n",
    "\n",
    "# Creating uncleaned data and the expected data, to test our cleaning function\n",
    "create_dirty_and_expected_data(\n",
    "    df_search,\n",
    "    'job_title',\n",
    "    'expected_job_category',\n",
    "    [\n",
    "        'foo',\n",
    "        'Data Analyst',\n",
    "        'Data Engineer',\n",
    "        'Data Scientist',\n",
    "        'data analyst'\n",
    "    ],\n",
    "    [\n",
    "        None,\n",
    "        'DA',\n",
    "        None,\n",
    "        None,\n",
    "        'DA'\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6b4b22ce-6653-4bda-ba25-7316eebc30c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        job_title expected_job_category job_category\n",
      "0             foo                  None         None\n",
      "1    Data Analyst                    DA           DA\n",
      "2   Data Engineer                  None         None\n",
      "3  Data Scientist                  None         None\n",
      "4    data analyst                    DA           DA\n",
      "5            None                  None         None\n",
      "6            None                  None         None\n",
      "7            None                  None         None\n",
      "8            None                  None         None\n",
      "9            None                  None         None\n"
     ]
    }
   ],
   "source": [
    "df = search_double_keyword(df_search, 'job_title', 'job_category', 'data','analyst', 'DA')\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc9c3457-1827-4926-b03c-1c0972422c8c",
   "metadata": {},
   "source": [
    "# Exporting the report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "a03a7a7b-0e62-43d9-a2cd-929facb6c53b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_report_t = df_report.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "6f87b2c7-cd8e-4dc3-a21d-24732430820b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_report_t.rename(columns={0: 'Occurrence'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "59adff57-9a00-4ece-b7e5-52a6dce8fad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_report_t.to_csv('../results/Cleaning_report.txt', sep='\\t', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d976e8f1-ba7f-49c3-bae3-bb937b1ca925",
   "metadata": {},
   "outputs": [],
   "source": [
    "del df_report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d02eb6fb-ad45-4454-a427-3ab3f8b1f2bc",
   "metadata": {},
   "source": [
    "# Reloading a module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d72703ce-2e4e-4720-8fec-a37c993f54b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reloading a module\n",
    "import importlib\n",
    "import sys\n",
    "\n",
    "# Add the parent directory of 'scripts' to the module search path\n",
    "sys.path.append('../')\n",
    "\n",
    "# Reload the module\n",
    "importlib.reload(scripts.clean_phone)\n",
    "from scripts.clean_phone import clean_phone"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f571e76-5cdc-443c-aa5f-f2319ebd3674",
   "metadata": {},
   "source": [
    "# Multi-level function implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61b2ee64-d137-470e-9956-6cccd033d48e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Playing with multi-level implementation of functions\n",
    "\n",
    "import sys\n",
    "sys.path.append('../')  # Add the main project directory to sys.path\n",
    "\n",
    "from scripts.func1 import do_something\n",
    "\n",
    "result = do_something()\n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data_analytics_01",
   "language": "python",
   "name": "data_analytics_01"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  },
  "toc-autonumbering": true,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
